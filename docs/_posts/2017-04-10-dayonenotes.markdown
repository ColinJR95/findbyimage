---
layout: post
title:  "Day 1 Notes"
date:   2017-04-10 21:52:15 -0700
tags: Notes
---

safe space / different kinds of knowldege tools
connecting the dots / wide view
maximum literacy and maximum access to resources - wayfinding




wont be teaching math or code or psychology or biology or philosophy
looking at high-level implementations of these approaches
	feel free to tinker!
	learn the basics enough to debug / combine / hack
as well as pre-built: wekinator, openframeworks

projects can take the form of critical writing, hacks, other dimensions

state of the field of AI: scattered, maybe will converge on one framework?
theory vs application. similar to early art interventions with other technologies (cv, video, internet

tradeoff: participating in open exchange of tools, knowledge and insight in a consolidated way (convergence), vs. preserving criticality, difference, diversity?

history:
lovelace
turing


rosenblatt - perceptron

image classification
limitations
cant do XOR

compare to logical gates?

minsky

other AI:
	Support Vector Machines
	decision forests
	boosting

early ML grew out of statistics / CV / DSP
	using expert knowledge to hand-craft feature engineering
	(classifiers / regressors)
	tools specific to domain (audio, image, text, etc)

problem of training, scaling

new ML derives from raw media (pixels / characters / words / samples)


timeline:

1980’s : geoff hinton - backpropagation / multilayer NN’s - training problem
1998: Yann LeCun - LeNet + handwritten check recognition
2006: CIFAR + deep learning conspiracy
2009: Convolutional NN (convnet) gets SOTA for speech-to-text
2010: first ImageNet challenge (yearly) - started w/ classical CV techniques
2012: AlexNet gets SOTA for image classification
	image classification is the basis - segmentation, description, etc. build on this
2013: ZFNet + deep learning investment boom
2014: theano, torch, keras, and other libraries / packages emerge
2015: creative boom w/ deep dream, stylenet
2016: resnets (image classification), tensorflow, alphago, research explosion


zoom out - theory / critical issues / wider applications

atari training - just looks at pixels and score (reward). one algorithm for various tasks
“transfer learning”


hive-mind clustering - tagging, annotating, added-data enriches objects

what is a feature?
characterization - treating “anything” as numerical data / parameterizable



anxiety over superintelligence?
artificial general intelligence
specific intelligence

importance of preserving different ways of knowing / different knowledge systems
problems of implicit bias and discrimination

algorithms that shape news and flow of information, human understanding of reality
rate of recidivism (propublica study)
financial systems
extra-judicial persecution
pressing concerns - climate change, inequality, problems of access etc
what does “open” really mean (in terms of tools, who’s providing them, datasets, etc)?

clear consideration of intentions + objectives
failure
ways of being “wrong”

what are poetics?
